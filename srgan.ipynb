{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---- srgan_training_eval.py ----\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import requests, zipfile, io\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import numpy as np\n",
        "import glob"
      ],
      "metadata": {
        "id": "PrBMX5MbUmsI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Download DIV2K Dataset ---\n",
        "def download_div2k(root_dir):\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\"\n",
        "    print(\"Downloading DIV2K HR dataset...\")\n",
        "    r = requests.get(url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(root_dir)\n",
        "\n",
        "    url_lr = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_bicubic_X4.zip\"\n",
        "    print(\"Downloading DIV2K LR dataset...\")\n",
        "    r = requests.get(url_lr)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall(root_dir)"
      ],
      "metadata": {
        "id": "OhTh-hyEUp45"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Resize"
      ],
      "metadata": {
        "id": "1K7vuo25Xs-2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Dataset Loader ---\n",
        "class DIV2KDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.hr_dir = os.path.join(root_dir, 'DIV2K_train_HR')\n",
        "        self.lr_dir = os.path.join(root_dir, 'DIV2K_train_LR_bicubic', 'X4')\n",
        "        self.hr_files = sorted(glob.glob(os.path.join(self.hr_dir, '*.png')))\n",
        "        self.lr_files = sorted(glob.glob(os.path.join(self.lr_dir, '*.png')))\n",
        "\n",
        "        self.hr_transform = transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        self.lr_transform = transforms.Compose([\n",
        "            transforms.Resize((64, 64)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr_img = Image.open(self.hr_files[idx]).convert('RGB')\n",
        "        lr_img = Image.open(self.lr_files[idx]).convert('RGB')\n",
        "        return self.lr_transform(lr_img), self.hr_transform(hr_img)"
      ],
      "metadata": {
        "id": "0W4YvZzKUvc-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generator ---\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(channels, channels, 3, 1, 1),\n",
        "            nn.BatchNorm2d(channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)"
      ],
      "metadata": {
        "id": "NFVRZcKeU0A4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorSR(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_residuals=16):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 9, 1, 4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(*[ResidualBlock(64) for _ in range(num_residuals)])\n",
        "        self.mid = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64)\n",
        "        )\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.Conv2d(64, 256, 3, 1, 1),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.PReLU(),\n",
        "            nn.Conv2d(64, 256, 3, 1, 1),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.final = nn.Conv2d(64, in_channels, 9, 1, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.initial(x)\n",
        "        x2 = self.res_blocks(x1)\n",
        "        x3 = self.mid(x2)\n",
        "        x = x1 + x3\n",
        "        x = self.upsample(x)\n",
        "        return self.final(x)"
      ],
      "metadata": {
        "id": "6adaaEEgU4tN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Discriminator ---\n",
        "class DiscriminatorSR(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        def conv_block(in_channels, out_channels, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, stride, 1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.LeakyReLU(0.2, inplace=True)\n",
        "            )\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            conv_block(3, 64, 1),\n",
        "            conv_block(64, 64, 2),\n",
        "            conv_block(64, 128, 1),\n",
        "            conv_block(128, 128, 2),\n",
        "            conv_block(128, 256, 1),\n",
        "            conv_block(256, 256, 2),\n",
        "            conv_block(256, 512, 1),\n",
        "            conv_block(512, 512, 2),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "Yr8fx_0zU7iU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Perceptual Loss using VGG19 ---\n",
        "class VGGFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        vgg19 = models.vgg19(pretrained=True).features\n",
        "        self.slice = nn.Sequential(*[vgg19[i] for i in range(36)])\n",
        "        for p in self.slice.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.slice(x)\n",
        "\n",
        "# --- GAN Loss ---\n",
        "def gan_loss(dis_real, dis_fake):\n",
        "    real_loss = F.binary_cross_entropy_with_logits(dis_real, torch.ones_like(dis_real))\n",
        "    fake_loss = F.binary_cross_entropy_with_logits(dis_fake, torch.zeros_like(dis_fake))\n",
        "    return real_loss + fake_loss"
      ],
      "metadata": {
        "id": "z4H9W4fOU-KG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Training Function ---\n",
        "def train(root_dir, epochs=10, batch_size=16, lr=1e-4, save_dir='results_srgan'):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    download_div2k(root_dir)\n",
        "    dataset = DIV2KDataset(root_dir)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "\n",
        "    generator = GeneratorSR().to(device)\n",
        "    discriminator = DiscriminatorSR().to(device)\n",
        "    feature_extractor = VGGFeatureExtractor().to(device)\n",
        "\n",
        "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.9, 0.999))\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        g_loss_total, d_loss_total = 0.0, 0.0\n",
        "        psnr_epoch, ssim_epoch = [], []\n",
        "\n",
        "        loop = tqdm(dataloader, desc=f\"Epoch [{epoch}/{epochs}]\")\n",
        "        for lr_imgs, hr_imgs in loop:\n",
        "            lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "\n",
        "            # Generator forward\n",
        "            fake_hr = generator(lr_imgs)\n",
        "            dis_fake = discriminator(fake_hr)\n",
        "            dis_real = discriminator(hr_imgs)\n",
        "\n",
        "            content_loss = F.mse_loss(feature_extractor(fake_hr), feature_extractor(hr_imgs))\n",
        "            adv_loss = gan_loss(dis_real, dis_fake)\n",
        "            pixel_loss = F.mse_loss(fake_hr, hr_imgs)\n",
        "            g_loss = content_loss + 1e-3 * adv_loss + pixel_loss\n",
        "\n",
        "            opt_g.zero_grad()\n",
        "            g_loss.backward()\n",
        "            opt_g.step()\n",
        "\n",
        "            # Discriminator forward\n",
        "            dis_real = discriminator(hr_imgs)\n",
        "            dis_fake = discriminator(fake_hr.detach())\n",
        "            d_loss = gan_loss(dis_real, dis_fake)\n",
        "\n",
        "            opt_d.zero_grad()\n",
        "            d_loss.backward()\n",
        "            opt_d.step()\n",
        "\n",
        "            g_loss_total += g_loss.item()\n",
        "            d_loss_total += d_loss.item()\n",
        "\n",
        "            # Metrics\n",
        "            for i in range(hr_imgs.size(0)):\n",
        "                gen_img = fake_hr[i].detach().cpu().numpy().transpose(1, 2, 0)\n",
        "                gt_img = hr_imgs[i].detach().cpu().numpy().transpose(1, 2, 0)\n",
        "                psnr_epoch.append(psnr(gt_img, gen_img, data_range=1.0))\n",
        "                ssim_epoch.append(ssim(gt_img, gen_img, channel_axis=-1, data_range=1.0, win_size=5))\n",
        "\n",
        "        avg_psnr = np.mean(psnr_epoch)\n",
        "        avg_ssim = np.mean(ssim_epoch)\n",
        "        print(f\"\\nEpoch {epoch}: G_Loss={g_loss_total:.4f}, D_Loss={d_loss_total:.4f}, PSNR={avg_psnr:.4f}, SSIM={avg_ssim:.4f}\")\n",
        "\n",
        "        save_image(fake_hr, os.path.join(save_dir, f\"gen_epoch_{epoch}.png\"))\n",
        "        save_image(hr_imgs, os.path.join(save_dir, f\"gt_epoch_{epoch}.png\"))\n"
      ],
      "metadata": {
        "id": "Ohho0-vyVFla"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(root_dir=\"data\", epochs=20, batch_size=16)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb-mkN96WVs2",
        "outputId": "956026ae-bea8-4cc4-f98f-2e46e36c49fa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading DIV2K HR dataset...\n",
            "Downloading DIV2K LR dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Epoch [1/20]: 100%|██████████| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: G_Loss=15.1875, D_Loss=36.5347, PSNR=15.6927, SSIM=0.1707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [2/20]: 100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: G_Loss=13.6784, D_Loss=7.6783, PSNR=18.3875, SSIM=0.2918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [3/20]: 100%|██████████| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: G_Loss=13.2451, D_Loss=3.2596, PSNR=18.6784, SSIM=0.3196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [4/20]: 100%|██████████| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: G_Loss=12.6648, D_Loss=0.7558, PSNR=18.8250, SSIM=0.3429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [5/20]: 100%|██████████| 50/50 [01:41<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5: G_Loss=11.8520, D_Loss=0.7488, PSNR=19.3278, SSIM=0.3736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [6/20]: 100%|██████████| 50/50 [01:40<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6: G_Loss=11.2667, D_Loss=7.7763, PSNR=19.6989, SSIM=0.4061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [7/20]: 100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: G_Loss=10.6405, D_Loss=0.7042, PSNR=20.1317, SSIM=0.4367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [8/20]: 100%|██████████| 50/50 [01:40<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8: G_Loss=10.2551, D_Loss=0.6451, PSNR=20.2980, SSIM=0.4540\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [9/20]: 100%|██████████| 50/50 [01:41<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9: G_Loss=9.8603, D_Loss=0.3111, PSNR=20.5785, SSIM=0.4655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [10/20]: 100%|██████████| 50/50 [01:40<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10: G_Loss=9.6089, D_Loss=0.3936, PSNR=20.5206, SSIM=0.4714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [11/20]: 100%|██████████| 50/50 [01:42<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 11: G_Loss=9.2974, D_Loss=1.3469, PSNR=20.7908, SSIM=0.4733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [12/20]: 100%|██████████| 50/50 [01:42<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 12: G_Loss=9.0673, D_Loss=0.2538, PSNR=20.9319, SSIM=0.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [13/20]: 100%|██████████| 50/50 [01:43<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 13: G_Loss=8.8900, D_Loss=0.1263, PSNR=20.8052, SSIM=0.4782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [14/20]: 100%|██████████| 50/50 [01:41<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 14: G_Loss=8.6925, D_Loss=0.1081, PSNR=20.8754, SSIM=0.4783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [15/20]: 100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 15: G_Loss=8.4603, D_Loss=0.0675, PSNR=20.9903, SSIM=0.4793\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [16/20]: 100%|██████████| 50/50 [01:41<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 16: G_Loss=8.2916, D_Loss=0.0990, PSNR=20.8745, SSIM=0.4778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [17/20]: 100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 17: G_Loss=8.0993, D_Loss=0.2380, PSNR=21.0113, SSIM=0.4767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [18/20]: 100%|██████████| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 18: G_Loss=7.9657, D_Loss=0.1030, PSNR=20.8988, SSIM=0.4752\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [19/20]: 100%|██████████| 50/50 [01:41<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 19: G_Loss=7.7901, D_Loss=0.0513, PSNR=20.9662, SSIM=0.4755\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch [20/20]: 100%|██████████| 50/50 [01:40<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 20: G_Loss=7.6448, D_Loss=0.0417, PSNR=21.0083, SSIM=0.4739\n"
          ]
        }
      ]
    }
  ]
}